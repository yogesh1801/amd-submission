{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0a1ce-c943-4d48-b403-89645ab95e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Read the parquet file\n",
    "df = pd.read_parquet('r_code_output_smaller_model.parquet')\n",
    "\n",
    "successful_tasks = []\n",
    "failed_tasks = []\n",
    "\n",
    "print(f\"Starting tests for {len(df)} tasks...\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "def run_r_test(idx, task_id, r_code, r_test):\n",
    "    full_code = f\"{r_code}\\n\\n{r_test}\"\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.R', delete=False) as f:\n",
    "        f.write(full_code)\n",
    "        temp_file = f.name\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['Rscript', temp_file],    # ‚úÖ Run using Rscript\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            return (\"success\", task_id, idx, result.stdout, result.stderr)\n",
    "        else:\n",
    "            return (\"failed\", task_id, idx, result.stdout, result.stderr, result.returncode)\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return (\"timeout\", task_id, idx, '', 'Test exceeded 30 second timeout', 'TIMEOUT')\n",
    "\n",
    "    except Exception as e:\n",
    "        return (\"exception\", task_id, idx, '', str(e), 'EXCEPTION')\n",
    "\n",
    "    finally:\n",
    "        if os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n",
    "\n",
    "\n",
    "# Number of threads ‚Äî adjust as needed\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    future_to_task = {\n",
    "        executor.submit(run_r_test, idx, row['task_id'], row['r_code'], row['r_test']): idx\n",
    "        for idx, row in df.iterrows()\n",
    "    }\n",
    "\n",
    "    for future in as_completed(future_to_task):\n",
    "        idx = future_to_task[future]\n",
    "        try:\n",
    "            status, task_id, row_index, stdout, stderr, *extra = future.result()\n",
    "            if status == \"success\":\n",
    "                print(f\"‚úÖ SUCCESS: {task_id} (Row {row_index + 1}/{len(df)})\")\n",
    "                successful_tasks.append(task_id)\n",
    "            elif status == \"failed\":\n",
    "                return_code = extra[0]\n",
    "                print(f\"‚ùå FAILED: {task_id} (Row {row_index + 1})\")\n",
    "                print(f\"   Error output: {stderr[:200]}...\")\n",
    "                failed_tasks.append({\n",
    "                    'task_id': task_id,\n",
    "                    'row_index': row_index,\n",
    "                    'return_code': return_code,\n",
    "                    'stderr': stderr,\n",
    "                    'stdout': stdout\n",
    "                })\n",
    "            elif status == \"timeout\":\n",
    "                print(f\"‚è±Ô∏è TIMEOUT: {task_id}\")\n",
    "                failed_tasks.append({\n",
    "                    'task_id': task_id,\n",
    "                    'row_index': row_index,\n",
    "                    'return_code': 'TIMEOUT',\n",
    "                    'stderr': stderr,\n",
    "                    'stdout': stdout\n",
    "                })\n",
    "            else:\n",
    "                print(f\"üí• ERROR: {task_id} - {stderr}\")\n",
    "                failed_tasks.append({\n",
    "                    'task_id': task_id,\n",
    "                    'row_index': row_index,\n",
    "                    'return_code': 'EXCEPTION',\n",
    "                    'stderr': stderr,\n",
    "                    'stdout': stdout\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"üí• ERROR in future: {e}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total tasks: {len(df)}\")\n",
    "print(f\"‚úÖ Successful: {len(successful_tasks)}\")\n",
    "print(f\"‚ùå Failed: {len(failed_tasks)}\")\n",
    "print(f\"Success rate: {len(successful_tasks)/len(df)*100:.2f}%\")\n",
    "\n",
    "if failed_tasks:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    failed_df = pd.DataFrame(failed_tasks)\n",
    "    failed_df.to_csv(f'failed_r_tasks_{timestamp}.csv', index=False)\n",
    "    print(f\"\\n‚ùå Failed tasks saved to: failed_r_tasks_{timestamp}.csv\")\n",
    "\n",
    "    print(\"\\nFailed task IDs:\")\n",
    "    for task in failed_tasks:\n",
    "        print(f\"  - {task['task_id']} (row {task['row_index']})\")\n",
    "else:\n",
    "    print(\"\\nüéâ All tasks passed!\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aace33-97eb-43d9-b397-96408e03a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the original parquet file\n",
    "df = pd.read_parquet('r_dataset.parquet')\n",
    "print(f\"Original dataset: {len(df)} rows\")\n",
    "\n",
    "failed_files = glob.glob('failed_r_tasks_*.csv')\n",
    "\n",
    "if not failed_files:\n",
    "    print(\"\\n‚ùå No failed_tasks CSV file found!\")\n",
    "    print(\"Please run the test script first to generate failed tasks.\")\n",
    "    exit()\n",
    "\n",
    "# Get the most recent file\n",
    "latest_failed_file = max(failed_files, key=lambda x: x.split('_')[2])\n",
    "print(f\"\\nUsing failed tasks from: {latest_failed_file}\")\n",
    "\n",
    "# Read the failed tasks\n",
    "failed_df = pd.read_csv(latest_failed_file)\n",
    "failed_task_ids = failed_df['task_id'].tolist()\n",
    "\n",
    "print(f\"Failed tasks to remove: {len(failed_task_ids)}\")\n",
    "print(f\"\\nFailed task IDs:\")\n",
    "for task_id in failed_task_ids:\n",
    "    print(f\"  - {task_id}\")\n",
    "\n",
    "# Remove failed tasks\n",
    "df_filtered = df[~df['task_id'].isin(failed_task_ids)]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Failed rows removed: {len(failed_task_ids)}\")\n",
    "print(f\"Remaining rows: {len(df_filtered)}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Save the filtered dataset\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f'cleaned_file_passed_only_{timestamp}.parquet'\n",
    "df_filtered.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Filtered dataset saved to: {output_file}\")\n",
    "print(f\"Success rate: {len(df_filtered)/len(df)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
